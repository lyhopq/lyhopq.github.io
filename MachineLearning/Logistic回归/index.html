<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta name="baidu-site-verification" content="OACP69rYUO" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  
  <title>Logistic回归 | 沧海一粟</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
    <meta name="author" content="Lyh">
  
  
    <meta name="description" content="基于Logistic回归和Sigmoid的分类Logistic回归分类器：
$$z=w^Tx$$$$x=(x_0, x_1, …, x_n) \qquad （待分类数据）$$$$w=(w_0, w_1, …, w_n) \qquad （最佳回归系数）$$$$\sigma(z)=\frac{1}{1+e^{-z}} \qquad（Sigmoid 函数）$$

当$\sigma(z)&amp;gt;0.5$时">
  
  <meta name="description" content="基于Logistic回归和Sigmoid的分类Logistic回归分类器：
$$z=w^Tx$$$$x=(x_0, x_1, …, x_n) \qquad （待分类数据）$$$$w=(w_0, w_1, …, w_n) \qquad （最佳回归系数）$$$$\sigma(z)=\frac{1}{1+e^{-z}} \qquad（Sigmoid 函数）$$

当$\sigma(z)&amp;gt;0.5$时">
<meta property="og:type" content="article">
<meta property="og:title" content="Logistic回归">
<meta property="og:url" content="http://lyhopq.github.io/MachineLearning/Logistic回归/index.html">
<meta property="og:site_name" content="沧海一粟">
<meta property="og:description" content="基于Logistic回归和Sigmoid的分类Logistic回归分类器：
$$z=w^Tx$$$$x=(x_0, x_1, …, x_n) \qquad （待分类数据）$$$$w=(w_0, w_1, …, w_n) \qquad （最佳回归系数）$$$$\sigma(z)=\frac{1}{1+e^{-z}} \qquad（Sigmoid 函数）$$

当$\sigma(z)&amp;gt;0.5$时">
<meta property="og:updated_time" content="2016-01-05T12:20:53.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Logistic回归">
<meta name="twitter:description" content="基于Logistic回归和Sigmoid的分类Logistic回归分类器：
$$z=w^Tx$$$$x=(x_0, x_1, …, x_n) \qquad （待分类数据）$$$$w=(w_0, w_1, …, w_n) \qquad （最佳回归系数）$$$$\sigma(z)=\frac{1}{1+e^{-z}} \qquad（Sigmoid 函数）$$

当$\sigma(z)&amp;gt;0.5$时">
  
    <link rel="alternate" href="/atom.xml" title="沧海一粟" type="application/atom+xml">
  
  
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <!--[if lt IE 9]><script src="//cdn.bootcss.com/html5shiv/3.7.0/html5shiv.min.js"></script><![endif]-->
  
  
<!-- //插入统计代码 -->

</head>

<body>
  <div class="wrapper">
    <header id="header">
  <div class="title">
    <h1><a href="/">沧海一粟</a></h1>
    <p><a href="/">在知识的海洋中翱翔</a></p>
  </div>
  <nav class="nav">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
      
        <li><a href="/atom.xml">RSS</a></li>
      
      <li>
    <form><input type="text" id="ts-search-input" class="ts-search-input" /></form>
    </li>
    </ul>
    <div class="clearfix"></div>
  </nav>
  <div class="clearfix"></div>
</header>

    <div class="content"><article class="post">
  <header>
    
      <div class="icon"></div>
      <a href="/MachineLearning/Logistic回归/">
  <time datetime="2013-08-26T16:00:00.000Z">
    8月 27 2013
  </time>
</a>
    
    
  
    <h1 class="title">Logistic回归</h1>
  

  </header>
  
  <div class="entry">
    
        
        <div id="toc" class="toc-article">
            <strong class="toc-title">目录</strong>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#基于Logistic回归和Sigmoid的分类"><span class="toc-text">基于Logistic回归和Sigmoid的分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基于最优化方法的最佳回归系数的确定"><span class="toc-text">基于最优化方法的最佳回归系数的确定</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度上升算法"><span class="toc-text">梯度上升算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#随机梯度上升算法"><span class="toc-text">随机梯度上升算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#改进的随机梯度上升算法"><span class="toc-text">改进的随机梯度上升算法</span></a></li></ol></li></ol>
        </div>
    
      <h2 id="基于Logistic回归和Sigmoid的分类">基于Logistic回归和Sigmoid的分类</h2><p>Logistic回归分类器：</p>
<p>$$z=w^Tx$$<br>$$x=(x_0, x_1, …, x_n) \qquad （待分类数据）$$<br>$$w=(w_0, w_1, …, w_n) \qquad （最佳回归系数）$$<br>$$\sigma(z)=\frac{1}{1+e^{-z}} \qquad（Sigmoid 函数）$$</p>
<ul>
<li>当$\sigma(z)&gt;0.5$时，数据被归为1类</li>
<li>当$\sigma(z)&lt;0.5$时，数据被归为0类</li>
</ul>
<h2 id="基于最优化方法的最佳回归系数的确定">基于最优化方法的最佳回归系数的确定</h2><p>函数$f(x,y)$的梯度表示为：<br>$$\nabla{f(x,y)}=\binom{\frac{\partial{f(x,y)}}{\partial{x}}}{\frac{\partial{f(x,y)}}{\partial{y}}}$$</p>
<p>梯度算法的迭代公式：<br>$$w:=w+\alpha\nabla_wf(w)$$</p>
<ul>
<li>$\alpha$ 移动步长</li>
<li>$\nabla_wf(w)$ 移动方向</li>
</ul>
<a id="more"></a>
<h3 id="梯度上升算法">梯度上升算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMatIn, classLabels)</span>:</span></span><br><span class="line">    dataMatrix = mat(dataMatIn)             <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    labelMat = mat(classLabels).transpose() <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.001</span></span><br><span class="line">    maxCycles = <span class="number">500</span></span><br><span class="line">    weights = ones((n,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):              <span class="comment">#heavy on matrix operations</span></span><br><span class="line">        h = sigmoid(dataMatrix*weights)     <span class="comment">#matrix mult</span></span><br><span class="line">        error = (labelMat - h)              <span class="comment">#vector subtraction</span></span><br><span class="line">        weights = weights + alpha * dataMatrix.transpose()* error <span class="comment">#matrix mult</span></span><br><span class="line">    <span class="keyword">return</span> weights</span><br></pre></td></tr></table></figure>
<ul>
<li>特点：每次更新回归系数时都要遍历整个数据集，计算复杂度太高。</li>
</ul>
<h3 id="随机梯度上升算法">随机梯度上升算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent0</span><span class="params">(dataMatrix, classLabels)</span>:</span></span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    weights = ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        h = sigmoid(sum(dataMatrix[i]*weights))</span><br><span class="line">        error = classLabels[i] - h</span><br><span class="line">        weights = weights + alpha * error * dataMatrix[i]</span><br><span class="line">    <span class="keyword">return</span> weights</span><br></pre></td></tr></table></figure>
<ul>
<li>特点：每次仅用一个样本点更新回归系数，是一个在线学习算法。</li>
</ul>
<h3 id="改进的随机梯度上升算法">改进的随机梯度上升算法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatrix, classLabels, numIter=<span class="number">150</span>)</span>:</span></span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    weights = ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</span><br><span class="line">        dataIndex = range(m)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            alpha = <span class="number">4</span>/(<span class="number">1.0</span>+j+i)+<span class="number">0.0001</span>    <span class="comment">#apha decreases with iteration, does not </span></span><br><span class="line">            randIndex = int(random.uniform(<span class="number">0</span>,len(dataIndex)))<span class="comment">#go to 0 because of the constant</span></span><br><span class="line">            h = sigmoid(sum(dataMatrix[randIndex]*weights))</span><br><span class="line">            error = classLabels[randIndex] - h</span><br><span class="line">            weights = weights + alpha * error * dataMatrix[randIndex]</span><br><span class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</span><br><span class="line">    <span class="keyword">return</span> weights</span><br></pre></td></tr></table></figure>
<ul>
<li>特点：<ol>
<li>$\alpha$在每次迭代的时候都会调整，这会缓解回归系数的高频波动；</li>
<li>$\alpha$从一个较大的值逐步减小并趋于常数（非0），与固定的$\alpha$相比，加快了算法的收敛速度；</li>
<li>通过随机选取样本来更新回归系数，将减少回归系数的周期性波动。</li>
</ol>
</li>
</ul>

      
  </div>
  <footer>
    
      
<div class="pagepart clearfix">
  
    <a href="/MachineLearning/决策树/" class="alignleft prev" title="决策树">决策树</a>
  
  
    <a href="/MachineLearning/朴素贝叶斯/" class="alignright next" title="朴素贝叶斯">朴素贝叶斯</a>
    
</div>


      
  <div class="categories">
    <a class="categories-link" href="/categories/机器学习/">机器学习</a>
  </div>

      
  <div class="tags">
    <a class="tags-link" href="/tags/Machine-Learning/">Machine Learning</a>, <a class="tags-link" href="/tags/分类器/">分类器</a>, <a class="tags-link" href="/tags/概率论/">概率论</a>
  </div>

      
    
    <div class="clearfix"></div>
  </footer>
</article>


<section id="comment">
  <h1 class="title">评论</h1>
  <div class="ds-thread" data-thread-key="MachineLearning/Logistic回归/" data-title="Logistic回归" data-url="http://lyhopq.github.io/MachineLearning/Logistic回归/"></div>
</section>

</div>
  </div>
  
  <div id="sidebar" class="widgets-bottom">
  
<div class="widget category">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/categories/C-C/">C/C++</a><small>5</small></li>
  
    <li><a href="/categories/Git/">Git</a><small>1</small></li>
  
    <li><a href="/categories/Golang/">Golang</a><small>2</small></li>
  
    <li><a href="/categories/Linux/">Linux</a><small>3</small></li>
  
    <li><a href="/categories/Python/">Python</a><small>22</small></li>
  
    <li><a href="/categories/UML/">UML</a><small>1</small></li>
  
    <li><a href="/categories/Vim/">Vim</a><small>1</small></li>
  
    <li><a href="/categories/业余/">业余</a><small>1</small></li>
  
    <li><a href="/categories/机器学习/">机器学习</a><small>5</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">标签云</h3>
  <div class="entry">
    <a href="/tags/ArchLinux/" style="font-size: 10px;">ArchLinux</a> <a href="/tags/Boot/" style="font-size: 10px;">Boot</a> <a href="/tags/C/" style="font-size: 18.33px;">C++</a> <a href="/tags/C-11/" style="font-size: 16.67px;">C++11</a> <a href="/tags/Coding-Style/" style="font-size: 10px;">Coding Style</a> <a href="/tags/DP/" style="font-size: 18.33px;">DP</a> <a href="/tags/Eclipse/" style="font-size: 10px;">Eclipse</a> <a href="/tags/GO/" style="font-size: 10px;">GO</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Golang/" style="font-size: 10px;">Golang</a> <a href="/tags/Gtest/" style="font-size: 10px;">Gtest</a> <a href="/tags/Inkscape/" style="font-size: 10px;">Inkscape</a> <a href="/tags/Linux/" style="font-size: 11.67px;">Linux</a> <a href="/tags/Linux-Command/" style="font-size: 10px;">Linux Command</a> <a href="/tags/Machine-Learning/" style="font-size: 16.67px;">Machine Learning</a> <a href="/tags/MinGW/" style="font-size: 10px;">MinGW</a> <a href="/tags/PlantUML/" style="font-size: 10px;">PlantUML</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/UML/" style="font-size: 10px;">UML</a> <a href="/tags/Unicode/" style="font-size: 10px;">Unicode</a> <a href="/tags/Utf-8/" style="font-size: 10px;">Utf-8</a> <a href="/tags/command/" style="font-size: 10px;">command</a> <a href="/tags/decode/" style="font-size: 10px;">decode</a> <a href="/tags/encode/" style="font-size: 10px;">encode</a> <a href="/tags/godef/" style="font-size: 10px;">godef</a> <a href="/tags/shell/" style="font-size: 11.67px;">shell</a> <a href="/tags/vim/" style="font-size: 11.67px;">vim</a> <a href="/tags/内存分配/" style="font-size: 10px;">内存分配</a> <a href="/tags/分类器/" style="font-size: 16.67px;">分类器</a> <a href="/tags/单元测试/" style="font-size: 10px;">单元测试</a> <a href="/tags/命令行解析/" style="font-size: 10px;">命令行解析</a> <a href="/tags/概率论/" style="font-size: 15px;">概率论</a> <a href="/tags/算法/" style="font-size: 10px;">算法</a> <a href="/tags/结构体对齐/" style="font-size: 10px;">结构体对齐</a> <a href="/tags/翻译/" style="font-size: 13.33px;">翻译</a>
  </div>
</div>


  
<div class="widget tag">
  <h3 class="title">最近发布</h3>
  <ul class="entry">
    
      <li>
        <a href="/《Effective-Modern-C-》学习笔记3/">《Effective Modern C++》条款3</a>
      </li>
    
      <li>
        <a href="/《Effective-Modern-C-》学习笔记2/">《Effective Modern C++》条款2</a>
      </li>
    
      <li>
        <a href="/《Effective-Modern-C-》学习笔记1/">《Effective Modern C++》条款1</a>
      </li>
    
      <li>
        <a href="/PEP-0008-Python代码风格指南/">PEP 0008 -- Python代码风格指南</a>
      </li>
    
      <li>
        <a href="/当DP遇见Py/当DP遇见Py(二十) -- 职责链模式/">当DP遇见Py(二十) -- 职责链模式</a>
      </li>
    
  </ul>
</div>

</div>
  
  <footer id="footer"><div class="copyright">
  
  &copy; 2016 <a href="/">Lyh</a>
  
</div>
<div class="theme-copyright">
  Theme by <a href="https://github.com/orderedlist" target="_blank">orderedlist</a>
   | 
  Redesign by <a href="http://blog.dafengning.com/" target="_blank">Chong Zi</a>
</div>
<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>
<div class="clearfix"></div>
<script async src="http://78rbbi.com1.z0.glb.clouddn.com/busuanzi.pure.mini.js">
</script>
</footer>
  <script src="//lib.sinaapp.com/js/jquery/1.8/jquery.min.js"></script>
<script src="/js/scale.fix.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var duoshuoQuery = {short_name:"lyhopq"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>


<div id="rightfix" style="display:none;">

<a href="#comment" id="gocomm" class="fix_btn" title="提问/评论"><i><i></i></i></a>


<a href="javascript:void(0)" id="gotop" class="fix_btn" onclick="gotop();" title="回到顶部"><i></i></a>
<script>
  function gotop(){
    $('html,body').animate({
        scrollTop : '0px'
      }, 800);
  }
  $(function(){
    _rightfix = $('#rightfix');
    $(window).scroll(function(){
      $sollTop = document.documentElement.scrollTop + document.body.scrollTop;
      if($sollTop > 350){
        _rightfix.show();
      }else{
        _rightfix.hide();
      }
    });
  });
</script>

</div>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
  (function($){
    $('.fancybox').fancybox();
  })(jQuery);
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    }); 
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



<script>
var option = {
  engineKey: '70e393f447ec0686ffba'
};
(function(w,d,t,u,n,s,e){
  s = d.createElement(t);
  s.src = u;
  s.async = 1;
  w[n] = function(r){
    w[n].opts = r;
  };
  e = d.getElementsByTagName(t)[0];
  e.parentNode.insertBefore(s, e);
})(window,document,'script','//tinysou-cdn.b0.upaiyun.com/ts.js','_ts');
_ts(option);

$("#ts-search-input").mouseenter(function(){
  $("#ts-search-input").animate({width:'+=150px',opacity:'+=0.4'},"slow")}).stop().mouseleave(function(){
  $("#ts-search-input").animate({width:'-=150px',opacity:'-=0.4'},"slow")});
</script>

</body>
</html>